{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure path to data: \n",
    "with open('src/config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Access the data paths\n",
    "data_store = config['data']['original_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/laptops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099    7150.47\n",
       "478     5999.00\n",
       "1202    5758.14\n",
       "1245    5630.90\n",
       "1475    5368.77\n",
       "Name: Final Price, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Final Price'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3936.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data[data['Brand'] == 'Dell']['Final Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/z9gxvfjj6jz9l2838bq01n100000gp/T/ipykernel_5520/1408859892.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Screen'].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# Step 1: Calculate the median value of the Screen column\n",
    "median_before = data['Screen'].median()\n",
    "\n",
    "# Step 2: Calculate the most frequent value (mode) of the Screen column\n",
    "mode_value = data['Screen'].mode()[0]\n",
    "\n",
    "# Step 3: Use the fillna method to fill the missing values in the Screen column with the most frequent value\n",
    "data['Screen'].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Step 4: Calculate the median value of the Screen column again\n",
    "median_after = data['Screen'].median()\n",
    "\n",
    "# Step 5: Compare the median values before and after filling the missing values\n",
    "if median_before == median_after:\n",
    "    print(\"No\")\n",
    "else:\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all the elements of the result: 91.29988062995753\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select all the \"Innjoo\" laptops from the dataset\n",
    "innjoo_laptops = data[data['Brand'] == 'Innjoo']\n",
    "\n",
    "# Step 2: Select only columns RAM, Storage, Screen\n",
    "selected_columns = innjoo_laptops[['RAM', 'Storage', 'Screen']]\n",
    "\n",
    "# Step 3: Get the underlying NumPy array. Let's call it X\n",
    "X = selected_columns.to_numpy()\n",
    "\n",
    "# Step 4: Compute matrix-matrix multiplication between the transpose of X and X. To get the transpose, use X.T. Let's call the result XTX\n",
    "XTX = X.T @ X\n",
    "\n",
    "# Step 5: Compute the inverse of XTX\n",
    "XTX_inv = np.linalg.inv(XTX)\n",
    "\n",
    "# Step 6: Create an array y with values [1100, 1300, 800, 900, 1000, 1100]\n",
    "y = np.array([1100, 1300, 800, 900, 1000, 1100])\n",
    "\n",
    "# Step 7: Multiply the inverse of XTX with the transpose of X, and then multiply the result by y. Call the result w\n",
    "w = XTX_inv @ X.T @ y\n",
    "\n",
    "# Step 8: Compute the sum of all the elements of the result\n",
    "sum_of_elements = np.sum(w)\n",
    "\n",
    "print(\"Sum of all the elements of the result:\", sum_of_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customizing th column \n",
    "data.columns = data.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['final_price'].plot(kind='hist', bins=20, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(16.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ram'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "n_val = int(n * 0.2)\n",
    "n_test = int(n * 0.2)\n",
    "n_train = n - n_val - n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.iloc[:n_train]\n",
    "df_val = data.iloc[n_train:n_train+n_val]\n",
    "df_test = data.iloc[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(n)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.iloc[idx[:n_train]]\n",
    "df_val = data.iloc[idx[n_train:n_train+n_val]]\n",
    "df_test = data.iloc[idx[n_train+n_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df = data  # Replace with your actual dataset\n",
    "\n",
    "# Shuffle the dataset with seed 42\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the dataset into train/val/test sets with 60%/20%/20% distribution\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 0: 617.48\n",
      "RMSE with mean: 617.48\n",
      "Both are equally good\n"
     ]
    }
   ],
   "source": [
    "# simple linear regression model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = data  # Replace with your actual dataset\n",
    "\n",
    "# Shuffle the dataset with seed 42\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the dataset into train/val/test sets with 60%/20%/20% distribution\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Convert non-numeric columns to numeric if possible\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "train_df = preprocess_data(train_df)\n",
    "val_df = preprocess_data(val_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "# Function to apply one-hot encoding and align columns\n",
    "def one_hot_encode_and_align(train_df, val_df, test_df):\n",
    "    # Combine all datasets to ensure all categories are included\n",
    "    combined_df = pd.concat([train_df, val_df, test_df])\n",
    "    combined_encoded_df = pd.get_dummies(combined_df, drop_first=True)\n",
    "\n",
    "    # Split the combined encoded DataFrame back into train, val, and test\n",
    "    train_encoded_df = combined_encoded_df.iloc[:len(train_df)]\n",
    "    val_encoded_df = combined_encoded_df.iloc[len(train_df):len(train_df) + len(val_df)]\n",
    "    test_encoded_df = combined_encoded_df.iloc[len(train_df) + len(val_df):]\n",
    "\n",
    "    return train_encoded_df, val_encoded_df, test_encoded_df\n",
    "\n",
    "# Apply one-hot encoding and align columns\n",
    "train_df, val_df, test_df = one_hot_encode_and_align(train_df, val_df, test_df)\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(train_df, val_df, fill_value):\n",
    "    # Fill missing values\n",
    "    train_df_filled = train_df.copy()\n",
    "    val_df_filled = val_df.copy()\n",
    "    train_df_filled.fillna(fill_value, inplace=True)\n",
    "    val_df_filled.fillna(fill_value, inplace=True)\n",
    "\n",
    "    # Prepare features and target\n",
    "    X_train = train_df_filled.drop(columns=['final_price'])\n",
    "    y_train = train_df_filled['final_price']\n",
    "    X_val = val_df_filled.drop(columns=['final_price'])\n",
    "    y_val = val_df_filled['final_price']\n",
    "\n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    return round(rmse, 2)\n",
    "\n",
    "# Fill with 0\n",
    "rmse_with_0 = train_and_evaluate(train_df, val_df, 0)\n",
    "\n",
    "# Fill with mean of the training set\n",
    "mean_screen = train_df['screen'].mean()\n",
    "rmse_with_mean = train_and_evaluate(train_df, val_df, mean_screen)\n",
    "\n",
    "# Compare RMSE\n",
    "print(f\"RMSE with 0: {rmse_with_0}\")\n",
    "print(f\"RMSE with mean: {rmse_with_mean}\")\n",
    "\n",
    "# Determine which option gives better RMSE\n",
    "if rmse_with_0 < rmse_with_mean:\n",
    "    print(\"With 0\")\n",
    "elif rmse_with_mean < rmse_with_0:\n",
    "    print(\"With mean\")\n",
    "else:\n",
    "    print(\"Both are equally good\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with r=0: 624.64\n",
      "RMSE with r=0.01: 617.48\n",
      "RMSE with r=0.1: 617.48\n",
      "RMSE with r=1: 617.48\n",
      "RMSE with r=5: 617.49\n",
      "RMSE with r=10: 617.5\n",
      "RMSE with r=100: 617.66\n",
      "Best r: 0.01\n"
     ]
    }
   ],
   "source": [
    "# using a regulization model:\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = data  # Replace with your actual dataset\n",
    "\n",
    "# Shuffle the dataset with seed 42\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the dataset into train/val/test sets with 60%/20%/20% distribution\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Convert non-numeric columns to numeric if possible\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "train_df = preprocess_data(train_df)\n",
    "val_df = preprocess_data(val_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "# Function to apply one-hot encoding and align columns\n",
    "def one_hot_encode_and_align(train_df, val_df, test_df):\n",
    "    # Combine all datasets to ensure all categories are included\n",
    "    combined_df = pd.concat([train_df, val_df, test_df])\n",
    "    combined_encoded_df = pd.get_dummies(combined_df, drop_first=True)\n",
    "\n",
    "    # Split the combined encoded DataFrame back into train, val, and test\n",
    "    train_encoded_df = combined_encoded_df.iloc[:len(train_df)]\n",
    "    val_encoded_df = combined_encoded_df.iloc[len(train_df):len(train_df) + len(val_df)]\n",
    "    test_encoded_df = combined_encoded_df.iloc[len(train_df) + len(val_df):]\n",
    "\n",
    "    return train_encoded_df, val_encoded_df, test_encoded_df\n",
    "\n",
    "# Apply one-hot encoding and align columns\n",
    "train_df, val_df, test_df = one_hot_encode_and_align(train_df, val_df, test_df)\n",
    "\n",
    "# Fill missing values with 0\n",
    "train_df.fillna(0, inplace=True)\n",
    "val_df.fillna(0, inplace=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X_train = train_df.drop(columns=['final_price'])\n",
    "y_train = train_df['final_price']\n",
    "X_val = val_df.drop(columns=['final_price'])\n",
    "y_val = val_df['final_price']\n",
    "\n",
    "# List of regularization parameters to try\n",
    "r_values = [0, 0.01, 0.1, 1, 5, 10, 100]\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, r):\n",
    "    # Train the model\n",
    "    model = Ridge(alpha=r)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    return round(rmse, 2)\n",
    "\n",
    "# Evaluate the model for each value of r\n",
    "rmse_scores = {}\n",
    "for r in r_values:\n",
    "    rmse_scores[r] = train_and_evaluate(X_train, y_train, X_val, y_val, r)\n",
    "\n",
    "# Print RMSE scores\n",
    "for r, rmse in rmse_scores.items():\n",
    "    print(f\"RMSE with r={r}: {rmse}\")\n",
    "\n",
    "# Determine which r gives the best RMSE\n",
    "best_r = min(rmse_scores, key=rmse_scores.get)\n",
    "print(f\"Best r: {best_r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of RMSE scores: 31.204\n"
     ]
    }
   ],
   "source": [
    "# TRYING DIFFERENT SEEDS TO SEE WHICH ONE GIVES THE BEST RMSE:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = data  # Replace with your actual dataset\n",
    "\n",
    "# List of seed values to try\n",
    "seed_values = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Convert non-numeric columns to numeric if possible\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Function to apply one-hot encoding and align columns\n",
    "def one_hot_encode_and_align(train_df, val_df, test_df):\n",
    "    # Combine all datasets to ensure all categories are included\n",
    "    combined_df = pd.concat([train_df, val_df, test_df])\n",
    "    combined_encoded_df = pd.get_dummies(combined_df, drop_first=True)\n",
    "\n",
    "    # Split the combined encoded DataFrame back into train, val, and test\n",
    "    train_encoded_df = combined_encoded_df.iloc[:len(train_df)]\n",
    "    val_encoded_df = combined_encoded_df.iloc[len(train_df):len(train_df) + len(val_df)]\n",
    "    test_encoded_df = combined_encoded_df.iloc[len(train_df) + len(val_df):]\n",
    "\n",
    "    return train_encoded_df, val_encoded_df, test_encoded_df\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(train_df, val_df):\n",
    "    # Fill missing values with 0\n",
    "    train_df.fillna(0, inplace=True)\n",
    "    val_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Prepare features and target\n",
    "    X_train = train_df.drop(columns=['final_price'])\n",
    "    y_train = train_df['final_price']\n",
    "    X_val = val_df.drop(columns=['final_price'])\n",
    "    y_val = val_df['final_price']\n",
    "\n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    return round(rmse, 2)\n",
    "\n",
    "# Collect RMSE scores for each seed\n",
    "rmse_scores = []\n",
    "\n",
    "for seed in seed_values:\n",
    "    # Shuffle the dataset with the current seed\n",
    "    df_shuffled = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # Split the dataset into train/val/test sets with 60%/20%/20% distribution\n",
    "    train_val_df, test_df = train_test_split(df_shuffled, test_size=0.2, random_state=seed)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=seed)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "    # Preprocess the data\n",
    "    train_df = preprocess_data(train_df)\n",
    "    val_df = preprocess_data(val_df)\n",
    "    test_df = preprocess_data(test_df)\n",
    "\n",
    "    # Apply one-hot encoding and align columns\n",
    "    train_df, val_df, test_df = one_hot_encode_and_align(train_df, val_df, test_df)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    rmse = train_and_evaluate(train_df, val_df)\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "# Compute the standard deviation of the RMSE scores\n",
    "std_dev = np.std(rmse_scores)\n",
    "std_dev_rounded = round(std_dev, 3)\n",
    "\n",
    "# Print the standard deviation\n",
    "print(f\"Standard deviation of RMSE scores: {std_dev_rounded}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test dataset: 574.12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = data  # Replace with your actual dataset\n",
    "\n",
    "# Shuffle the dataset with seed 9\n",
    "df = df.sample(frac=1, random_state=9).reset_index(drop=True)\n",
    "\n",
    "# Split the dataset into train/val/test sets with 60%/20%/20% distribution\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=9)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=9)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Combine train and validation datasets\n",
    "combined_train_val_df = pd.concat([train_df, val_df])\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Convert non-numeric columns to numeric if possible\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "combined_train_val_df = preprocess_data(combined_train_val_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "# Function to apply one-hot encoding and align columns\n",
    "def one_hot_encode_and_align(train_df, test_df):\n",
    "    # Combine all datasets to ensure all categories are included\n",
    "    combined_df = pd.concat([train_df, test_df])\n",
    "    combined_encoded_df = pd.get_dummies(combined_df, drop_first=True)\n",
    "\n",
    "    # Split the combined encoded DataFrame back into train and test\n",
    "    train_encoded_df = combined_encoded_df.iloc[:len(train_df)]\n",
    "    test_encoded_df = combined_encoded_df.iloc[len(train_df):]\n",
    "\n",
    "    return train_encoded_df, test_encoded_df\n",
    "\n",
    "# Apply one-hot encoding and align columns\n",
    "combined_train_val_df, test_df = one_hot_encode_and_align(combined_train_val_df, test_df)\n",
    "\n",
    "# Fill missing values with 0\n",
    "combined_train_val_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X_train_val = combined_train_val_df.drop(columns=['final_price'])\n",
    "y_train_val = combined_train_val_df['final_price']\n",
    "X_test = test_df.drop(columns=['final_price'])\n",
    "y_test = test_df['final_price']\n",
    "\n",
    "# Train the model with r=0.001\n",
    "model = Ridge(alpha=0.001)\n",
    "model.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Predict and evaluate on the test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_rounded = round(rmse, 2)\n",
    "\n",
    "# Print the RMSE on the test dataset\n",
    "print(f\"RMSE on the test dataset: {rmse_rounded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### \n",
    "#Logistic regression model\n",
    "\n",
    "bank_data = pd.read_csv('data/bank/bank-full.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = bank_data[['age', 'job', 'marital', 'education','balance', 'housing','contact','day','month','duration','campaign', 'pdays', 'previous', 'poutcome', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "housing      0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values:\n",
    "missing_values = bank_data.isnull().sum()\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'secondary'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check most frequent value in the column education:\n",
    "education_mode = bank_data['education'].mode()[0]\n",
    "education_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'balance', 'housing', 'contact',\n",
      "       'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome',\n",
      "       'y'],\n",
      "      dtype='object')\n",
      "Correlation between age and balance: 0.09778273937134745\n",
      "Correlation between day and campaign: 0.1624902163261929\n",
      "Correlation between day and pdays: -0.09304407377294062\n",
      "Correlation between pdays and previous: 0.45481963548050136\n",
      "The highest correlation is between pdays-previous with a value of 0.45481963548050136\n"
     ]
    }
   ],
   "source": [
    "# Print column names to verify\n",
    "print(bank_data.columns)\n",
    "\n",
    "# Check correlation between age and balance:\n",
    "if 'age' in bank_data.columns and 'balance' in bank_data.columns:\n",
    "    cor1 = bank_data['age'].corr(bank_data['balance'])\n",
    "    print(f\"Correlation between age and balance: {cor1}\")\n",
    "else:\n",
    "    print(\"Column 'age' or 'balance' not found in the DataFrame.\")\n",
    "\n",
    "# Check correlation between day and campaign:\n",
    "if 'day' in bank_data.columns and 'campaign' in bank_data.columns:\n",
    "    cor2 = bank_data['day'].corr(bank_data['campaign'])\n",
    "    print(f\"Correlation between day and campaign: {cor2}\")\n",
    "else:\n",
    "    print(\"Column 'day' or 'campaign' not found in the DataFrame.\")\n",
    "\n",
    "# Check correlation between day and pdays:\n",
    "if 'day' in bank_data.columns and 'pdays' in bank_data.columns:\n",
    "    cor3 = bank_data['day'].corr(bank_data['pdays'])\n",
    "    print(f\"Correlation between day and pdays: {cor3}\")\n",
    "else:\n",
    "    print(\"Column 'day' or 'pdays' not found in the DataFrame.\")\n",
    "\n",
    "# Check correlation between pdays and previous:\n",
    "if 'pdays' in bank_data.columns and 'previous' in bank_data.columns:\n",
    "    cor4 = bank_data['pdays'].corr(bank_data['previous'])\n",
    "    print(f\"Correlation between pdays and previous: {cor4}\")\n",
    "else:\n",
    "    print(\"Column 'pdays' or 'previous' not found in the DataFrame.\")\n",
    "\n",
    "# Determine which correlation is the highest:\n",
    "correlations = {\n",
    "    'age-balance': cor1 if 'age' in bank_data.columns and 'balance' in bank_data.columns else None,\n",
    "    'day-campaign': cor2 if 'day' in bank_data.columns and 'campaign' in bank_data.columns else None,\n",
    "    'day-pdays': cor3 if 'day' in bank_data.columns and 'pdays' in bank_data.columns else None,\n",
    "    'pdays-previous': cor4 if 'pdays' in bank_data.columns and 'previous' in bank_data.columns else None\n",
    "}\n",
    "\n",
    "# Filter out None values before finding the max\n",
    "correlations = {k: v for k, v in correlations.items() if v is not None}\n",
    "\n",
    "if correlations:\n",
    "    max_corr = max(correlations, key=correlations.get)\n",
    "    print(f\"The highest correlation is between {max_corr} with a value of {correlations[max_corr]}\")\n",
    "else:\n",
    "    print(\"No valid correlations found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the y variable:\n",
    "bank_data['y'] = bank_data['y'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bank_data_full_train, bank_data_test = train_test_split(bank_data, test_size=0.2, random_state=42)\n",
    "bank_data_train, bank_data_val = train_test_split(bank_data_full_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28934, 7234, 9043)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bank_data_train), len(bank_data_val), len(bank_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = bank_data_train.reset_index(drop=True)\n",
    "df_val = bank_data_val.reset_index(drop=True)\n",
    "df_test = bank_data_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.y.values\n",
    "y_val = df_val.y.values\n",
    "y_test = df_test.y.values\n",
    "\n",
    "del df_train['y']\n",
    "del df_val['y']\n",
    "del df_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "def mutual_info_churn_score(series):\n",
    "    return mutual_info_score(series, bank_data_full_train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\n",
    "    'job',\n",
    "    'marital',\n",
    "    'education',\n",
    "    'housing',\n",
    "    'contact',\n",
    "    'month',\n",
    "    'poutcome'\n",
    "]\n",
    "\n",
    "numerical = [\n",
    "    'age',\n",
    "    'balance',\n",
    "    'day',\n",
    "    'duration',\n",
    "    'campaign',\n",
    "    'pdays',\n",
    "    'previous'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poutcome     0.029257\n",
       "month        0.024774\n",
       "contact      0.014164\n",
       "housing      0.009800\n",
       "job          0.007765\n",
       "education    0.002458\n",
       "marital      0.002019\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = bank_data_full_train[categorical].apply(mutual_info_churn_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation dataset: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_val is the target variable for the validation dataset\n",
    "accuracy = model.score(X_val, y_val)\n",
    "\n",
    "# Round the accuracy to 2 decimal digits\n",
    "accuracy_rounded = round(accuracy, 2)\n",
    "\n",
    "print(f\"Accuracy on the validation dataset: {accuracy_rounded}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least useful feature is: contact\n",
      "Difference in accuracy without this feature: -0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a model with all features and record the accuracy\n",
    "model_all_features = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model_all_features.fit(X_train, y_train)\n",
    "original_accuracy = model_all_features.score(X_val, y_val)\n",
    "\n",
    "# Initialize variables to store the results\n",
    "accuracy_differences = {}\n",
    "\n",
    "# Exclude each original feature one by one and train a model without it\n",
    "for feature in categorical + numerical:\n",
    "    # Create a copy of the training and validation data without the current feature\n",
    "    train_dict_reduced = df_train.drop(columns=[feature]).to_dict(orient='records')\n",
    "    val_dict_reduced = df_val.drop(columns=[feature]).to_dict(orient='records')\n",
    "\n",
    "    X_train_reduced = dv.fit_transform(train_dict_reduced)\n",
    "    X_val_reduced = dv.transform(val_dict_reduced)\n",
    "\n",
    "    # Train a model without the current feature\n",
    "    model_reduced = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "    # Calculate the accuracy without the current feature\n",
    "    accuracy_reduced = model_reduced.score(X_val_reduced, y_val)\n",
    "\n",
    "    # Calculate the difference in accuracy\n",
    "    accuracy_difference = original_accuracy - accuracy_reduced\n",
    "    accuracy_differences[feature] = accuracy_difference\n",
    "\n",
    "# Find the feature with the smallest difference\n",
    "least_useful_feature = min(accuracy_differences, key=accuracy_differences.get)\n",
    "\n",
    "print(f\"The least useful feature is: {least_useful_feature}\")\n",
    "print(f\"Difference in accuracy without this feature: {accuracy_differences[least_useful_feature]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least useful feature is: marital\n",
      "Difference in accuracy without this feature: -0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a model with all features and record the accuracy\n",
    "model_all_features = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model_all_features.fit(X_train, y_train)\n",
    "original_accuracy = model_all_features.score(X_val, y_val)\n",
    "\n",
    "# Initialize variables to store the results\n",
    "features_to_test = ['age', 'balance', 'marital', 'previous']\n",
    "accuracy_differences = {}\n",
    "\n",
    "# Exclude each specified feature one by one and train a model without it\n",
    "for feature in features_to_test:\n",
    "    # Create a copy of the training and validation data without the current feature\n",
    "    train_dict_reduced = df_train.drop(columns=[feature]).to_dict(orient='records')\n",
    "    val_dict_reduced = df_val.drop(columns=[feature]).to_dict(orient='records')\n",
    "\n",
    "    X_train_reduced = dv.fit_transform(train_dict_reduced)\n",
    "    X_val_reduced = dv.transform(val_dict_reduced)\n",
    "\n",
    "    # Train a model without the current feature\n",
    "    model_reduced = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "    # Calculate the accuracy without the current feature\n",
    "    accuracy_reduced = model_reduced.score(X_val_reduced, y_val)\n",
    "\n",
    "    # Calculate the difference in accuracy\n",
    "    accuracy_difference = original_accuracy - accuracy_reduced\n",
    "    accuracy_differences[feature] = accuracy_difference\n",
    "\n",
    "# Find the feature with the smallest difference\n",
    "least_useful_feature = min(accuracy_differences, key=accuracy_differences.get)\n",
    "\n",
    "print(f\"The least useful feature is: {least_useful_feature}\")\n",
    "print(f\"Difference in accuracy without this feature: {accuracy_differences[least_useful_feature]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least useful feature is: marital\n",
      "Difference in accuracy without this feature: -0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a model with all features and record the accuracy\n",
    "model_all_features = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model_all_features.fit(X_train, y_train)\n",
    "original_accuracy = model_all_features.score(X_val, y_val)\n",
    "\n",
    "# Initialize variables to store the results\n",
    "features_to_test = ['age', 'balance', 'marital', 'previous']\n",
    "accuracy_differences = {}\n",
    "\n",
    "# Exclude each specified feature one by one and train a model without it\n",
    "for feature in features_to_test:\n",
    "    # Create a copy of the training and validation data without the current feature\n",
    "    train_dict_reduced = df_train.drop(columns=[feature]).to_dict(orient='records')\n",
    "    val_dict_reduced = df_val.drop(columns=[feature]).to_dict(orient='records')\n",
    "\n",
    "    # Fit the DictVectorizer on the reduced training data\n",
    "    dv_reduced = DictVectorizer(sparse=False)\n",
    "    X_train_reduced = dv_reduced.fit_transform(train_dict_reduced)\n",
    "    X_val_reduced = dv_reduced.transform(val_dict_reduced)\n",
    "\n",
    "    # Train a model without the current feature\n",
    "    model_reduced = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "    # Calculate the accuracy without the current feature\n",
    "    accuracy_reduced = model_reduced.score(X_val_reduced, y_val)\n",
    "\n",
    "    # Calculate the difference in accuracy\n",
    "    accuracy_difference = original_accuracy - accuracy_reduced\n",
    "    accuracy_differences[feature] = accuracy_difference\n",
    "\n",
    "# Find the feature with the smallest difference\n",
    "least_useful_feature = min(accuracy_differences, key=accuracy_differences.get)\n",
    "\n",
    "print(f\"The least useful feature is: {least_useful_feature}\")\n",
    "print(f\"Difference in accuracy without this feature: {accuracy_differences[least_useful_feature]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of C that leads to the best accuracy on the validation set is: 0.1\n",
      "Best accuracy: 0.901\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the values of C to try\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Initialize a dictionary to store the accuracies for each C\n",
    "accuracies = {}\n",
    "\n",
    "# Train models with different values of C and record the accuracy\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_val, y_val)\n",
    "    accuracies[C] = round(accuracy, 3)\n",
    "\n",
    "# Find the value of C that leads to the best accuracy\n",
    "best_C = max(accuracies, key=accuracies.get)\n",
    "best_accuracy = accuracies[best_C]\n",
    "\n",
    "print(f\"The value of C that leads to the best accuracy on the validation set is: {best_C}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of subscription: 0.759\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the Dictionary Vectorizer and model from files\n",
    "with open('src/models/dv.bin', 'rb') as f_dv:\n",
    "    dv = pickle.load(f_dv)\n",
    "\n",
    "with open('src/models/model1.bin', 'rb') as f_model:\n",
    "    model = pickle.load(f_model)\n",
    "\n",
    "# Client data\n",
    "client = {\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n",
    "\n",
    "# Transform the client data using the Dictionary Vectorizer\n",
    "X = dv.transform([client])\n",
    "\n",
    "# Get the prediction probability\n",
    "probability = model.predict_proba(X)[0][1]\n",
    "print(f'Probability of subscription: {probability:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'subscription_probability': 0.33480703475511053}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL (assuming local server)\n",
    "url = \"http://localhost:9696/predict\"\n",
    "\n",
    "# Define the client data\n",
    "client = {\n",
    "    \"job\": \"student\",\n",
    "    \"duration\": 280,\n",
    "    \"poutcome\": \"failure\"\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(url, json=client)\n",
    "\n",
    "# Look at the response\n",
    "print(response.status_code)  # Should be 200 if successful\n",
    "print(response.json())  # Should show the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=9696): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x123646300>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m~/CONDA/anaconda3/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CONDA/anaconda3/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/CONDA/anaconda3/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/connection.py:214\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x123646300>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=9696): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x123646300>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:9696/predict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanagement\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m400\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoutcome\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe probability that this client will get a subscription is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubscription_probability\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Documents/06-Repositories/ml-training-course/ml_training_course/lib/python3.12/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=9696): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x123646300>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:9696/predict\"\n",
    "client = {\"job\": \"management\", \"duration\": 400, \"poutcome\": \"success\"}\n",
    "response = requests.post(url, json=client).json()\n",
    "\n",
    "print(f\"The probability that this client will get a subscription is: {response['subscription_probability']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_training_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
